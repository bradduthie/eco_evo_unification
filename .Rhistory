species  <- c("species_1", "species_2");
sim_pval <- 0;
while(sim_pval > 0.05 | sim_pval < 0.0001){
species_eg  <- sample(x = species, size = 100, replace = TRUE);
species1    <- as.numeric(species_eg == "species_1");
species2    <- as.numeric(species_eg == "species_2");
error       <- rnorm(n = 100, mean = 0, sd = 40);
height      <- 400 + (species1 * 20) + error;
species_ID  <- as.factor(species_eg);
plant_data  <- data.frame(height, species_ID);
sim_mod     <- lm(plant_data$height ~ 1 + plant_data$species_ID);
sim_pval    <- summary(sim_mod)$coefficients[2,4];
}
sim_pval
write.table
?write.csv
tt
tt$estimate
tt$estimate[1]
as.numeric(tt$estimate[1])
?data.frame
?line
?line
ls()
plant_data
summary(aov(plant_data$height ~ plant_data$species_DI))
summary(aov(plant_data$height ~ plant_data$species_ID))
summary(aov(plant_data$height ~ plant_data$species_ID)) -> t2
t2
t2[1]
t2[2]
attributes(t2)
attributes$summary.aov
t2$summary.aov
t2
t2$class
t2$listof
t2$Df
t2
t2$Residuals
summary.aov(t2)
aov(plant_data$height ~ plant_data$species_ID) -> t2
summary.aov(t2)
summary.aov(t2)$Df
summary(t2)
summary(t2)[[1]]
summary(t2)[[1]][["Pr(>F)"]]
summary(t2)[["Pr(>F)"]]
summary(t2)[[1]][["Pr(>F)"]][1]
plant_data
tapply(X = plant_data$height, INDEX = plant_data$species_ID, FUN = mean)
tapply(X = plant_data$height, INDEX = plant_data$species_ID, FUN = mean) -> t1
t1[1\] - t1[2]
t1[1] - t1[2]
as.numeric(t1[1] - t1[2])
plant_data
null_diff  <- NULL;  # Place where the random diffs will go
iterations <- 9999;  # Number of reshuffles
iter       <- 1;     # Start with the first
while(iter < iterations){
new_species_ID  <- sample(x    = plant_data$species_ID,
size = length(plant_data$species_ID));
new_species     <- tapply(X = plant_data$height, INDEX = new_species_ID,
FUN = sum);
new_diffs       <- as.numeric( new_species[1] - new_species[2] );
}
}
plant_data
tapply(X = plant_data$height, INDEX = plant_data$species_ID, fun = mean);
unique(plant_data$species_ID)
tapply(X = plant_data$height, INDEX = as.character(plant_data$species_ID), fun = mean);
tapply(X = plant_data$height, INDEX = plant_data$species_ID, fun = sum);
plant_data$height
plant_data$species_ID
tapply(X = plant_data$height, INDEX = plant_data$species_ID, fun = mean);
tapply(X = plant_data$species_ID, INDEX = plant_data$height, fun = mean);
tapply(X = plant_data$height, INDEX = plant_data$species_ID,
FUN = mean);
145 + 26.54
x  <- rnorm(n = 100, mean = 20, sd = 5);
b0 <- 10;
b1 <- -1/2;
ep <- rnorm(n = 100, mean = 0, sd = 4);
y  <- b0 + (b1 * x) + ep;
lm(y)
lm(y~x)
x  <- rnorm(n = 500, mean = 20, sd = 5);
b0 <- 10;
b1 <- -1/2;
ep <- rnorm(n = 500, mean = 0, sd = 4);
y  <- b0 + (b1 * x) + ep;
lm(y~x)
x  <- rnorm(n = 500, mean = 20, sd = 5);
b0 <- 10;
b1 <- -1/2;
ep <- rnorm(n = 500, mean = 0, sd = 4);
y  <- b0 + (b1 * x) + ep;
lm(y~x)
x  <- rnorm(n = 500, mean = 20, sd = 5);
b0 <- 10;
b1 <- -1/2;
ep <- rnorm(n = 500, mean = 0, sd = 4);
y  <- b0 + (b1 * x) + ep;
lm(y~x)
x  <- rnorm(n = 500, mean = 20, sd = 5);
b0 <- 10;
b1 <- -1/2;
ep <- rnorm(n = 500, mean = 0, sd = 4);
y  <- b0 + (b1 * x) + ep;
lm(y~x)
x  <- rnorm(n = 1000, mean = 20, sd = 5);
b0 <- 10;
b1 <- -1/2;
ep <- rnorm(n = 1000, mean = 0, sd = 4);
y  <- b0 + (b1 * x) + ep;
lm(y~x)
x  <- rnorm(n = 1000, mean = 20, sd = 5);
b0 <- 10;
b1 <- -1/2;
ep <- rnorm(n = 1000, mean = 0, sd = 4);
y  <- b0 + (b1 * x) + ep;
lm(y~x)
summary(lm(y~x))
hist(x)
plot(x = x , y = y);
(1 * 9.34665) + (19.76476 * -0.46474) - 1.566933
(1 * 10) + (19.76476 * -0.5) - 1.566933
x_groups <- c("Group_1", "Group_2"); # All the possible groups
x        <- sample(x = x_groups, size = 1000, replace = TRUE); # Sample groups
b0       <- 10;
b1       <- -1/2;
ep       <- rnorm(n = 1000, mean = 0, sd = 4);
# Now is a challenging part -- we need to set X to a binary, is_group_2
is_group_2 <- as.numeric( x_groups == "Group_2" );
y          <- b0 + (b1 * is_group_2) + ep;
y
plot(x = x, y = y)
plot(x = is_group_2, y = y)
x_groups <- c("Group_1", "Group_2"); # All the possible groups
x        <- sample(x = x_groups, size = 1000, replace = TRUE); # Sample groups
b0       <- 10;
b1       <- -1/2;
ep       <- rnorm(n = 1000, mean = 0, sd = 4);
# Now is a challenging part -- we need to set X to a binary, is_group_2
is_group_2 <- as.numeric( x_groups == "Group_2" );
y          <- b0 + (b1 * is_group_2) + ep;
plot(x = is.group_2, y = y)
plot(x = is_group_2, y = y)
length(is_group_2)
x_groups <- c("Group_1", "Group_2"); # All the possible groups
x        <- sample(x = x_groups, size = 1000, replace = TRUE); # Sample groups
b0       <- 10;
b1       <- -1/2;
ep       <- rnorm(n = 1000, mean = 0, sd = 4);
# Now is a challenging part -- we need to set X to a binary, is_group_2
is_group_2 <- as.numeric( x == "Group_2" );
y          <- b0 + (b1 * is_group_2) + ep;
y
x
plot(x = is_group_2, y = y)
x_groups <- c("Group_1", "Group_2"); # All the possible groups
x        <- sample(x = x_groups, size = 1000, replace = TRUE); # Sample groups
b0       <- 10;
b1       <- -1/2;
ep       <- rnorm(n = 1000, mean = 0, sd = 4);
# Now is a challenging part -- we need to set X to a binary, is_group_2
is_group_2 <- as.numeric( x == "Group_2" );
y          <- b0 + (b1 * is_group_2) + ep;
# Try plotting the below
plot(x = is_group_2, y = y);
#Now we can use a linear model as before.
mod1 <- lm(y ~ x);
print(mod1);
summary(mod1);
9.9197 - 2.833
9.9197 - 0.658
10 - 0.658
10 - (0.5*20) + 4 + (20*0.8) + 1
library(irr)
citation("irr")
setwd("~/Dropbox/projects/func_trait_rev/lit_review")
dat <- read.csv("extra_10.csv");
doi <- unique(dat[,2]);
doi
which(dat[,2] == doi[1]);
which(dat[,2] == doi[2]);
which(dat[,2] == doi[3]);
which(dat[,2] == doi[4]);
which(dat[,2] == doi[5]);
dat
75*2
library(irr);
x10  <- read.csv(file = "extra_10.csv", header = TRUE); # The data
udo <- as.character(unique(x10$Article_DOI));
tot <- length(udo);
dat <- NULL;
peo <- NULL;
cou <- 1;
for(i in 1:tot){
papers    <- x10[x10$Article_DOI == udo[i],];
if(dim(papers)[1] == 2){
dat[[cou]]  <- t(as.matrix(papers[,3:(dim(x10)[2] - 1)]));
colnames(dat[[cou]]) <- papers[,dim(x10)[2]];
peo                  <- rbind(peo, colnames(dat[[cou]]));
cou                  <- cou + 1;
}
}
peo
x10
peo
# Now go through dat and peo and find overlap.
peop <- unique(peo[,1]);
kmat <- matrix(data = 0, nrow = length(peop), ncol = length(peop));
rownames(kmat) <- peop;
colnames(kmat) <- peop;
kmat
# Now go through dat and peo and find overlap.
peop <- unique(peo[,1]);
kmat <- matrix(data = NA, nrow = length(peop), ncol = length(peop));
rownames(kmat) <- peop;
colnames(kmat) <- peop;
kmat
aut_comp <- list();
for(i in 1:dim(kmat)[1]){
for(j in 1:dim(kmat)[2]){
aut1 <- peop[i];
aut2 <- peop[j];
litm <- paste(aut1,"_",aut2, sep = "");
for(k in 1:length(dat)){
authors <- colnames(dat[[k]]);
if(aut1 %in% authors & aut2 %in% authors & aut1 != aut2){
if(is.null(aut_comp[[litm]]) == TRUE){
aut_comp[[litm]] <- dat[[k]][4:dim(dat[[k]])[1],];
}else{
dat_aut <- colnames(dat[[k]]);
if(dat_aut[1] == colnames(aut_comp[[litm]])[1]){
col1             <- dat[[k]][4:dim(dat[[k]])[1], 1];
col2             <- dat[[k]][4:dim(dat[[k]])[1], 2];
add_dat          <- cbind(col1, col2);
aut_comp[[litm]] <- rbind(aut_comp[[litm]], add_dat);
}else{
col1             <- dat[[k]][4:dim(dat[[k]])[1], 2];
col2             <- dat[[k]][4:dim(dat[[k]])[1], 1];
add_dat          <- cbind(col1, col2);
aut_comp[[litm]] <- rbind(aut_comp[[litm]], add_dat);
}
}
}
if(aut1 == authors[1] & aut2 == authors[2] & aut1 == aut2){
add_dat          <- dat[[k]][4:dim(dat[[k]])[1],];
aut_comp[[litm]] <- rbind(aut_comp[[litm]], add_dat);
}
}
}
}
aut_comp
for(i in 1:length(aut_comp)){
kap_val <- kappa2(aut_comp[[i]])$value;
aut1    <- colnames(aut_comp[[i]])[1];
aut2    <- colnames(aut_comp[[i]])[2];
row     <- which(rownames(kmat) == aut1);
col     <- which(colnames(kmat) == aut2);
if(row < col){
temp <- row;
row  <- col;
col  <- temp;
}
kmat[row, col] <- kap_val;
}
among_authors  <- mean(kmat[lower.tri(kmat)]);
within_authors <- mean(diag(kmat));
kmat
among_authors
among_authors  <- mean(kmat[lower.tri(kmat)], na.rm = TRUE);
within_authors <- mean(diag(kmat), na.rm = TRUE);
among_authors
within_authors
dim(aut_comp)
lapply(aut_comp, dim)
ls()
head(x1)
head(x10)
table(x10$Co.author)
x10
x10[x10$Co.author = "Brad"] <- "Reviewer_1"
x10[x10$Co.author == "Brad"] <- "Reviewer_1"
x10$Co.author
kmat
x10  <- read.csv(file = "extra_10.csv", header = TRUE); # The data
udo <- as.character(unique(x10$Article_DOI));
tot <- length(udo);
dat <- NULL;
peo <- NULL;
cou <- 1;
for(i in 1:tot){
papers    <- x10[x10$Article_DOI == udo[i],];
if(dim(papers)[1] == 2){
dat[[cou]]  <- t(as.matrix(papers[,3:(dim(x10)[2] - 1)]));
colnames(dat[[cou]]) <- papers[,dim(x10)[2]];
peo                  <- rbind(peo, colnames(dat[[cou]]));
cou                  <- cou + 1;
}
}
# Now go through dat and peo and find overlap.
peop <- unique(peo[,1]);
kmat <- matrix(data = NA, nrow = length(peop), ncol = length(peop));
rownames(kmat) <- peop;
colnames(kmat) <- peop;
# Get responses for the same paper between two authors
aut_comp <- list();
for(i in 1:dim(kmat)[1]){
for(j in 1:dim(kmat)[2]){
aut1 <- peop[i];
aut2 <- peop[j];
litm <- paste(aut1,"_",aut2, sep = "");
for(k in 1:length(dat)){
authors <- colnames(dat[[k]]);
if(aut1 %in% authors & aut2 %in% authors & aut1 != aut2){
if(is.null(aut_comp[[litm]]) == TRUE){
aut_comp[[litm]] <- dat[[k]][4:dim(dat[[k]])[1],];
}else{
dat_aut <- colnames(dat[[k]]);
if(dat_aut[1] == colnames(aut_comp[[litm]])[1]){
col1             <- dat[[k]][4:dim(dat[[k]])[1], 1];
col2             <- dat[[k]][4:dim(dat[[k]])[1], 2];
add_dat          <- cbind(col1, col2);
aut_comp[[litm]] <- rbind(aut_comp[[litm]], add_dat);
}else{
col1             <- dat[[k]][4:dim(dat[[k]])[1], 2];
col2             <- dat[[k]][4:dim(dat[[k]])[1], 1];
add_dat          <- cbind(col1, col2);
aut_comp[[litm]] <- rbind(aut_comp[[litm]], add_dat);
}
}
}
if(aut1 == authors[1] & aut2 == authors[2] & aut1 == aut2){
add_dat          <- dat[[k]][4:dim(dat[[k]])[1],];
aut_comp[[litm]] <- rbind(aut_comp[[litm]], add_dat);
}
}
}
}
# Calculate the kappa matrix
for(i in 1:length(aut_comp)){
kap_val <- kappa2(aut_comp[[i]])$value;
aut1    <- colnames(aut_comp[[i]])[1];
aut2    <- colnames(aut_comp[[i]])[2];
row     <- which(rownames(kmat) == aut1);
col     <- which(colnames(kmat) == aut2);
if(row < col){
temp <- row;
row  <- col;
col  <- temp;
}
kmat[row, col] <- kap_val;
}
among_authors  <- mean(kmat[lower.tri(kmat)], na.rm = TRUE);
within_authors <- mean(diag(kmat), na.rm = TRUE);
kmat
among_authors
within_authors
kmat[kmat == NA]
setwd("~/Dropbox/projects/func_trait_rev/lit_review")
################################################################################
################################################################################
# Replicate paper assessment
################################################################################
################################################################################
# install.packages("irr")
library(irr);
x10  <- read.csv(file = "extra_10.csv", header = TRUE);
udo <- as.character(unique(x10$Article_DOI));
tot <- length(udo);
dat <- NULL;
peo <- NULL;
cou <- 1;
for(i in 1:tot){
papers    <- x10[x10$Article_DOI == udo[i],];
if(dim(papers)[1] == 2){
dat[[cou]]  <- t(as.matrix(papers[,3:(dim(x10)[2] - 1)]));
colnames(dat[[cou]]) <- papers[,dim(x10)[2]];
peo                  <- rbind(peo, colnames(dat[[cou]]));
cou                  <- cou + 1;
}
}
peop <- unique(peo[,1]);
kmat <- matrix(data = 0, nrow = length(peop), ncol = length(peop));
rownames(kmat) <- peop;
colnames(kmat) <- peop;
# Apologies for the messy code below
aut_comp <- list();
for(i in 1:dim(kmat)[1]){
for(j in 1:dim(kmat)[2]){
aut1 <- peop[i];
aut2 <- peop[j];
litm <- paste(aut1,"_",aut2, sep = "");
for(k in 1:length(dat)){
authors <- colnames(dat[[k]]);
if(aut1 %in% authors & aut2 %in% authors & aut1 != aut2){
if(is.null(aut_comp[[litm]]) == TRUE){
aut_comp[[litm]] <- dat[[k]][4:dim(dat[[k]])[1],];
}else{
dat_aut <- colnames(dat[[k]]);
if(dat_aut[1] == colnames(aut_comp[[litm]])[1]){
col1             <- dat[[k]][4:dim(dat[[k]])[1], 1];
col2             <- dat[[k]][4:dim(dat[[k]])[1], 2];
add_dat          <- cbind(col1, col2);
aut_comp[[litm]] <- rbind(aut_comp[[litm]], add_dat);
}else{
col1             <- dat[[k]][4:dim(dat[[k]])[1], 2];
col2             <- dat[[k]][4:dim(dat[[k]])[1], 1];
add_dat          <- cbind(col1, col2);
aut_comp[[litm]] <- rbind(aut_comp[[litm]], add_dat);
}
}
}
if(aut1 == authors[1] & aut2 == authors[2] & aut1 == aut2){
add_dat          <- dat[[k]][4:dim(dat[[k]])[1],];
aut_comp[[litm]] <- rbind(aut_comp[[litm]], add_dat);
}
}
}
}
aut_comp[[1]]
dat <- cbind(c(5,2, 1), c(6, 2, 1))
dat
rownames <- c("High", "Medium", "Low")
colnames <- c("Shetland", "Orkney")
rownames(dat) <- c("High", "Medium", "Low")
colnames(dat) <- c("Shetland", "Orkney")
dat
kappa2(dat)
Western <- c(6, 2, 0)
dat <- cbind(dat, Western)
dat
kappa2(dat)
?kappa2
kappam.light(dat)
setwd("~/Dropbox/projects/func_trait_rev/lit_review")
setwd("~/loc_sim/temp")
dat <- read.csv(file = "harleen_data.csv", header = TRUE, row.names = TRUE);
dat <- read.csv(file = "harleen_data.csv", header = TRUE);
head(dat)
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";");
head(dat)
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
dat
library("irr");
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
kappam.light(dat)
kappam.light(dat[,1:5])
kappam.light(dat[,1:3])
library("irr");
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
kappam.light(dat[,1:3])
dat[,1:3]
library("irr");
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
kappam.light(dat)
dat
library("irr");
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
kappam.light(dat[,2:5])
library("irr");
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
kappam.light(dat[,2:4])
dat
dim(dat)
library("irr");
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
kappam.light(dat[,33:35])
library("irr");
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
kappam.light(dat[,34:35])
library("irr");
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
kappam.light(dat[,33:34])
library("irr");
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
kappam.light(dat[,32:34])
library("irr");
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
kappam.light(t(dat[,32:34]))
library("irr");
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
kappam.light(dat[,32:34])
?kappam.light
library("irr");
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
kappam.fleiss(dat);
library("irr");
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
kripp.alpha(dat);
library("irr");
dat <- read.csv(file = "harleen_data.csv", header = TRUE, sep = ";",
row.names = 1);
kappam.fleiss(dat);
setwd("~/Dropbox/projects/UNICOP/unification")
